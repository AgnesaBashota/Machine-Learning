{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfde86dd",
   "metadata": {},
   "source": [
    "# DS24 Kunskapskontroll 2 – RAG-baserad chattbot\n",
    "\n",
    "Notebook med teoretiska svar och en praktisk implementation av en RAG-pipeline.\n",
    "Kör cellerna uppifrån och ned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ba1c3",
   "metadata": {},
   "source": [
    "## 1. Miljö & installation\n",
    "Kör följande för att installera beroenden lokalt. Om du kör i en miljö där du redan har dessa paket kan du hoppa över installationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1158ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation (kör vid behov)\n",
    "# !pip install -q faiss-cpu sentence-transformers langchain langchain-community langchain-core langchain-text-splitters pypdf tiktoken openai python-dotenv\n",
    "# Om du vill använda OpenAI: skapa en .env med OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e0557",
   "metadata": {},
   "source": [
    "## 2. Importer och konfiguration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b78f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path('docs')\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "PERSONAL_HANDBOK = DATA_DIR / 'personalhandbok.txt'\n",
    "if not PERSONAL_HANDBOK.exists():\n",
    "    PERSONAL_HANDBOK.write_text('Detta är en plats för din personliga handbok. Lägg in dina riktlinjer här.', encoding='utf-8')\n",
    "\n",
    "print('Datafolder:', DATA_DIR.resolve())\n",
    "print('Personlig handbok finns:', PERSONAL_HANDBOK.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa126a4",
   "metadata": {},
   "source": [
    "## 3. Datainläsning & chunking läser in `docs/personalhandbok.txt` (och ev. andra `.txt`/`.pdf`) och delar upp innehållet i mindre segment för att indexeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d12095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_corpus():\n",
    "    texts = []\n",
    "    for p in DATA_DIR.glob('**/*'):\n",
    "        if p.suffix.lower() == '.txt':\n",
    "            texts.append(p.read_text(encoding='utf-8', errors='ignore'))\n",
    "        # För PDF kan pypdf användas, utelämnat här för enkelhet\n",
    "    return \"\\n\\n\".join(texts)\n",
    "\n",
    "raw_text = load_corpus()\n",
    "print('Antal tecken i korpus:', len(raw_text))\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100, separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    ")\n",
    "chunks = splitter.split_text(raw_text)\n",
    "print('Antal chunks:', len(chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a40cc7",
   "metadata": {},
   "source": [
    "## 4. Embeddings & vektorindex (FAISS) använder `sentence-transformers` lokalt för att skapa embeddings och bygger ett FAISS-index för snabb sökning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92691e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"  # liten, snabb\n",
    "embedder = SentenceTransformer(model_name)\n",
    "\n",
    "emb = embedder.encode(chunks, convert_to_numpy=True, show_progress_bar=True)\n",
    "index = faiss.IndexFlatIP(emb.shape[1])\n",
    "faiss.normalize_L2(emb)\n",
    "index.add(emb)\n",
    "\n",
    "def retrieve(query, k=5):\n",
    "    qv = embedder.encode([query], convert_to_numpy=True)\n",
    "    faiss.normalize_L2(qv)\n",
    "    D, I = index.search(qv, k)\n",
    "    return [chunks[i] for i in I[0]]\n",
    "\n",
    "print('Index klart.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e024e",
   "metadata": {},
   "source": [
    "## 5. En enkel RAG-kedja (retrieval + generering)\n",
    "Här använder en **enkel** generator som bara sammanställer kontext och ger ett svar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_answer(query, k=5):\n",
    "    ctx = retrieve(query, k=k)\n",
    "    context_text = \"\\n\\n\".join([f\"- {c}\" for c in ctx])\n",
    "        # Här producerar vi ett deterministiskt svar baserat på kontexten.\n",
    "    answer = f\"Fråga: {query}\\n\\nKontext (top-{k}):\\n{context_text}\\n\\n\" \\             f\"Sammanfattning: Baserat på kontexten ovan kan vi se nyckelpunkter relaterade till frågan. \" \\             f\"Anpassa gärna till en riktig LLM för bättre svar.\"\n",
    "    return answer\n",
    "\n",
    "print(simple_answer(\"Vad står i min personliga handbok?\")[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1235f122",
   "metadata": {},
   "source": [
    "## 6. Utvärdering (enkel)\n",
    "Som en mycket enkel sanity check kör några testfrågor och verifierar att dokumentrelevanta passager hittas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "    \"Vad är syftet med handboken?\",\n",
    "    \"Vilka riktlinjer nämns?\"\n",
    "]\n",
    "for q in test_questions:\n",
    "    ctx = retrieve(q, k=3)\n",
    "    print(\"\\n=====\", q, \"=====\")\n",
    "    for i, c in enumerate(ctx, 1):\n",
    "        print(f\"[{i}] {c[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aaadf3",
   "metadata": {},
   "source": [
    "## 7. Diskussion och förbättringar\n",
    "- Byt ut `simple_answer` mot en riktig LLM (OpenAI, Azure OpenAI, Llama.cpp, vLLM etc.).\n",
    "- Lägg till källcitatsstöd: returnera vilka chunks som användes.\n",
    "- Lägg till eval med t.ex. *RAGAS* eller manuella Q/A-par.\n",
    "- Hårda krav på reprod. och mätbara mål: latency, precision@k, faithfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d2780",
   "metadata": {},
   "source": [
    "## 8. Teori – korta svar\n",
    "Nedan är kortfattade, kursrelevanta svar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089a7e0c",
   "metadata": {},
   "source": [
    "### 8.1 Bias–varians och överanpassning\n",
    "- **Bias**: fel p.g.a. förenklade antaganden; **Varians**: känslighet för träningsdata.\n",
    "- Överfitting minskas med regularisering (L2, dropout), mer data, data augmentation, tidig stoppning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23037bf2",
   "metadata": {},
   "source": [
    "### 8.2 Optimerare & inlärningshastighet\n",
    "- Vanliga optimerare: SGD, Adam, AdamW.\\\n",
    "- Välj `learning rate` via scheman (cosine, step) och `warmup`; för högt ger divergens, för lågt långsam konvergens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb25f33",
   "metadata": {},
   "source": [
    "### 8.3 Aktiverings- och förlustfunktioner\n",
    "- Aktiveringar: ReLU/GeLU (deep nets), Sigmoid/Tanh (sekvens/klassiska).\\\n",
    "- Förluster: CE för klassificering, MSE för regression, triplet/contrastive för representationer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84b179",
   "metadata": {},
   "source": [
    "### 8.4 CNN vs RNN vs Transformer\n",
    "- **CNN**: bra för bilder/2D-struktur. **RNN**: sekvenser; svårt med långa beroenden. **Transformer**: self-attention, skalbar och SOTA i språk/vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf96dc",
   "metadata": {},
   "source": [
    "### 8.5 RAG: nyckelkomponenter\n",
    "- Datainhämtning → chunking → embeddings → vektorindex → retriever → generator → citat/utvärdering.\\\n",
    "- Risker: hallucinationer, dålig chunking/metadata, driftsäkerhet."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
